{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_BF = pd.read_csv('BlackFriday-Copy1.csv', sep=',', encoding='latin1')\n",
    "data_BF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 537577 entries, 0 to 537576\n",
      "Data columns (total 12 columns):\n",
      "User_ID                       537577 non-null int64\n",
      "Product_ID                    537577 non-null object\n",
      "Gender                        537577 non-null object\n",
      "Age                           537577 non-null object\n",
      "Occupation                    537577 non-null int64\n",
      "City_Category                 537577 non-null object\n",
      "Stay_In_Current_City_Years    537577 non-null object\n",
      "Marital_Status                537577 non-null int64\n",
      "Product_Category_1            537577 non-null int64\n",
      "Product_Category_2            370591 non-null float64\n",
      "Product_Category_3            164278 non-null float64\n",
      "Purchase                      537577 non-null int64\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 49.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_BF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что ряд атрибутов имеют тип object. Кроме того атрибуты Product_Catagory_1 и Product_Catagory_2 имеют нулевые значения. \n",
    "С помощью метода value_counts() какие категории существуют у категориальных атрибутов и сколько киентов  им принадлежат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    405380\n",
       "F    132197\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-35    214690\n",
       "36-45    107499\n",
       "18-25     97634\n",
       "46-50     44526\n",
       "51-55     37618\n",
       "55+       20903\n",
       "0-17      14707\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     70862\n",
       "0     68120\n",
       "7     57806\n",
       "1     45971\n",
       "17    39090\n",
       "20    32910\n",
       "12    30423\n",
       "14    26712\n",
       "2     25845\n",
       "16    24790\n",
       "6     19822\n",
       "3     17366\n",
       "10    12623\n",
       "5     11985\n",
       "15    11812\n",
       "11    11338\n",
       "19     8352\n",
       "13     7548\n",
       "18     6525\n",
       "9      6153\n",
       "8      1524\n",
       "Name: Occupation, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"Occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    226493\n",
       "C    166446\n",
       "A    144638\n",
       "Name: City_Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"City_Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     189192\n",
       "2      99459\n",
       "3      93312\n",
       "4+     82889\n",
       "0      72725\n",
       "Name: Stay_In_Current_City_Years, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"Stay_In_Current_City_Years\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    317817\n",
       "1    219760\n",
       "Name: Marital_Status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"Marital_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод describe() отображает сводку по числовым  атрибутам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_BF_without_ID=data_BF.drop([\"User_ID\",  \"Marital_Status\"] , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>537577.00000</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>370591.000000</td>\n",
       "      <td>164278.000000</td>\n",
       "      <td>537577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.08271</td>\n",
       "      <td>5.295546</td>\n",
       "      <td>9.842144</td>\n",
       "      <td>12.669840</td>\n",
       "      <td>9333.859853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.52412</td>\n",
       "      <td>3.750701</td>\n",
       "      <td>5.087259</td>\n",
       "      <td>4.124341</td>\n",
       "      <td>4981.022133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5866.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23961.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Occupation  Product_Category_1  Product_Category_2  \\\n",
       "count  537577.00000       537577.000000       370591.000000   \n",
       "mean        8.08271            5.295546            9.842144   \n",
       "std         6.52412            3.750701            5.087259   \n",
       "min         0.00000            1.000000            2.000000   \n",
       "25%         2.00000            1.000000            5.000000   \n",
       "50%         7.00000            5.000000            9.000000   \n",
       "75%        14.00000            8.000000           15.000000   \n",
       "max        20.00000           18.000000           18.000000   \n",
       "\n",
       "       Product_Category_3       Purchase  \n",
       "count       164278.000000  537577.000000  \n",
       "mean            12.669840    9333.859853  \n",
       "std              4.124341    4981.022133  \n",
       "min              3.000000     185.000000  \n",
       "25%              9.000000    5866.000000  \n",
       "50%             14.000000    8062.000000  \n",
       "75%             16.000000   12073.000000  \n",
       "max             18.000000   23961.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF_without_ID.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постоим гистограммы числовых атрибутов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8042390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "data_BF_without_ID.hist(bins=50, figsize=(20,15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание испытательного набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data_BF, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430061 train + 107516 test\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80541</th>\n",
       "      <td>1000411</td>\n",
       "      <td>P00117442</td>\n",
       "      <td>F</td>\n",
       "      <td>46-50</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469742</th>\n",
       "      <td>1000352</td>\n",
       "      <td>P00136142</td>\n",
       "      <td>M</td>\n",
       "      <td>18-25</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477144</th>\n",
       "      <td>1001474</td>\n",
       "      <td>P00029242</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139704</th>\n",
       "      <td>1003589</td>\n",
       "      <td>P00113142</td>\n",
       "      <td>F</td>\n",
       "      <td>46-50</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52739</th>\n",
       "      <td>1002025</td>\n",
       "      <td>P00145642</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "80541   1000411  P00117442      F  46-50           1             B   \n",
       "469742  1000352  P00136142      M  18-25           4             A   \n",
       "477144  1001474  P00029242      M  26-35           4             A   \n",
       "139704  1003589  P00113142      F  46-50           0             B   \n",
       "52739   1002025  P00145642      M    55+          13             C   \n",
       "\n",
       "       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "80541                           0               1                   5   \n",
       "469742                          0               0                   6   \n",
       "477144                          2               1                   8   \n",
       "139704                          1               1                   1   \n",
       "52739                           3               0                   1   \n",
       "\n",
       "        Product_Category_2  Product_Category_3  Purchase  \n",
       "80541                 14.0                 NaN      8757  \n",
       "469742                16.0                 NaN      8644  \n",
       "477144                 NaN                 NaN      6129  \n",
       "139704                 5.0                12.0     11585  \n",
       "52739                  8.0                17.0     15273  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что атрибут Age является важным атрибутом для прогнозирования Purchase. Постороим стратифицированную выборку на основе категории возраста "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data_BF, data_BF[\"Age\"]):\n",
    "    strat_train_set = data_BF.loc[train_index]\n",
    "    strat_test_set = data_BF.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-35    0.399364\n",
       "36-45    0.199970\n",
       "18-25    0.181619\n",
       "46-50    0.082825\n",
       "51-55    0.069980\n",
       "55+      0.038887\n",
       "0-17     0.027354\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set[\"Age\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-35    0.399366\n",
       "36-45    0.199969\n",
       "18-25    0.181619\n",
       "46-50    0.082827\n",
       "51-55    0.069977\n",
       "55+      0.038884\n",
       "0-17     0.027358\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BF[\"Age\"].value_counts() / len(data_BF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_proportions(data):\n",
    "    return data[\"Age\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(data_BF, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": age_proportions(data_BF),\n",
    "    \"Stratified\": age_proportions(strat_test_set),\n",
    "    \"Random\": age_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Random</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Rand. %error</th>\n",
       "      <th>Strat. %error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-17</th>\n",
       "      <td>0.027358</td>\n",
       "      <td>0.027540</td>\n",
       "      <td>0.027354</td>\n",
       "      <td>0.665788</td>\n",
       "      <td>-0.014157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18-25</th>\n",
       "      <td>0.181619</td>\n",
       "      <td>0.183117</td>\n",
       "      <td>0.181619</td>\n",
       "      <td>0.824969</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26-35</th>\n",
       "      <td>0.399366</td>\n",
       "      <td>0.399847</td>\n",
       "      <td>0.399364</td>\n",
       "      <td>0.120546</td>\n",
       "      <td>-0.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36-45</th>\n",
       "      <td>0.199969</td>\n",
       "      <td>0.200212</td>\n",
       "      <td>0.199970</td>\n",
       "      <td>0.121303</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46-50</th>\n",
       "      <td>0.082827</td>\n",
       "      <td>0.081969</td>\n",
       "      <td>0.082825</td>\n",
       "      <td>-1.035902</td>\n",
       "      <td>-0.002804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51-55</th>\n",
       "      <td>0.069977</td>\n",
       "      <td>0.069255</td>\n",
       "      <td>0.069980</td>\n",
       "      <td>-1.031973</td>\n",
       "      <td>0.004759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55+</th>\n",
       "      <td>0.038884</td>\n",
       "      <td>0.038059</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>-2.119859</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Overall    Random  Stratified  Rand. %error  Strat. %error\n",
       "0-17   0.027358  0.027540    0.027354      0.665788      -0.014157\n",
       "18-25  0.181619  0.183117    0.181619      0.824969       0.000466\n",
       "26-35  0.399366  0.399847    0.399364      0.120546      -0.000558\n",
       "36-45  0.199969  0.200212    0.199970      0.121303       0.000372\n",
       "46-50  0.082827  0.081969    0.082825     -1.035902      -0.002804\n",
       "51-55  0.069977  0.069255    0.069980     -1.031973       0.004759\n",
       "55+    0.038884  0.038059    0.038887     -2.119859       0.009010"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая пропорции возраста в полном объеме данных, в испытательном наборе, который сгенерирован посредством стратифицированной выборки, и в испытательном наборе, полученном  с применением случайной выборки, имеем, что испытательный набор, полученный с помощью стратифицированной выборки имеет пропорции, идентичные проциям полного набора данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим копию обучающего набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для подготовки данных. Т.к. атрибуты \"Product_Category_2\", \"Product_Category_3\" имееют значения NaN, необхидимо провести очистку данных. Существует три варианта:\n",
    "1. Удалить строки, содержащие NaN;\n",
    "2. Удалить атрибуты, содержащие NaN;\n",
    "3. Заменить NaN мат. ожиданием этого атрибута (Imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "def prepare (X, drop_col = False, drop_row = False, imputer1 = True):\n",
    "    \n",
    "    if drop_col:\n",
    "        BF_col = X.dropna(subset=[\"Product_Category_2\", \"Product_Category_3\"])\n",
    "        return BF_col\n",
    "    elif drop_row:\n",
    "        BF_row = X.drop([\"Product_Category_2\", \"Product_Category_3\"], axis=1)\n",
    "        return BF_row\n",
    "    else:\n",
    "        imputer = Imputer (strategy = 'median')\n",
    "        imputer.fit(X)\n",
    "        Y = imputer.transform(X)\n",
    "        BF_imput = pd.DataFrame(Y, columns=X.columns, index = list(BF.index.values))\n",
    "        return BF_imput  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. данных достаточно много, попробуем вариант с удалением соответвсующих строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134097</th>\n",
       "      <td>1002701</td>\n",
       "      <td>P00037142</td>\n",
       "      <td>M</td>\n",
       "      <td>46-50</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114745</th>\n",
       "      <td>1005711</td>\n",
       "      <td>P00296042</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172040</th>\n",
       "      <td>1002600</td>\n",
       "      <td>P00015642</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>14</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68335</th>\n",
       "      <td>1004449</td>\n",
       "      <td>P00046742</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>12</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233837</th>\n",
       "      <td>1000025</td>\n",
       "      <td>P00066242</td>\n",
       "      <td>M</td>\n",
       "      <td>18-25</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "134097  1002701  P00037142      M  46-50           1             A   \n",
       "114745  1005711  P00296042      M  26-35           7             C   \n",
       "172040  1002600  P00015642      M  26-35          14             C   \n",
       "68335   1004449  P00046742      M  26-35          12             C   \n",
       "233837  1000025  P00066242      M  18-25           4             C   \n",
       "\n",
       "       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "134097                          3               1                   1   \n",
       "114745                         4+               0                   8   \n",
       "172040                          1               1                   8   \n",
       "68335                          4+               1                   1   \n",
       "233837                         4+               0                   1   \n",
       "\n",
       "        Product_Category_2  Product_Category_3  Purchase  \n",
       "134097                 2.0                 5.0      7585  \n",
       "114745                13.0                16.0      3998  \n",
       "172040                16.0                17.0      7964  \n",
       "68335                  2.0                15.0     15334  \n",
       "233837                 2.0                 5.0     15773  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_prep = prepare(BF, drop_col = True, drop_row = False, imputer1 = False)\n",
    "BF_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_data = BF_prep.drop(\"Purchase\", axis=1)\n",
    "BF_labels = BF_prep[\"Purchase\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from future_encoders import OneHotEncoder\n",
    "\n",
    "def coder_cat (X,  one_hot_cat=True, share_cat = False):\n",
    "    BF_cat_Use = X[\"User_ID\"]\n",
    "    BF_cat_Prod = X[\"Product_ID\"]\n",
    "    BF_cat_Gen = X[\"Gender\"]\n",
    "    BF_cat_Age = X[\"Age\"]\n",
    "    BF_cat_CC = X[\"City_Category\"]\n",
    "    BF_cat_SCCY = X[\"Stay_In_Current_City_Years\"]\n",
    "    BF_cat_MS = X[\"Marital_Status\"]\n",
    "    BF_cat_Prod1 = X[\"Product_Category_1\"]\n",
    "    BF_cat_Prod2 = X[\"Product_Category_2\"]\n",
    "    BF_cat_Prod3 = X[\"Product_Category_3\"]\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "        \n",
    "    BF_cat_Use_encoded, BF_categories_Use = BF_cat_Use.factorize()\n",
    "    BF_cat_Prod_encoded, BF_categories_Prod = BF_cat_Prod.factorize()\n",
    "    BF_cat_Gen_encoded, BF_categories_Gen = BF_cat_Gen.factorize()\n",
    "    BF_cat_Age_encoded, BF_categories_Age = BF_cat_Age.factorize()\n",
    "    BF_cat_CC_encoded, BF_categories_CC = BF_cat_CC.factorize()\n",
    "    BF_cat_SCCY_encoded, BF_categories_SCCY = BF_cat_SCCY.factorize()\n",
    "    BF_cat_MS_encoded, BF_categories_MS = BF_cat_MS.factorize() \n",
    "    BF_cat_Prod1_encoded, BF_categories_Prod1 = BF_cat_Prod1.factorize()\n",
    "    BF_cat_Prod2_encoded, BF_categories_Prod2 = BF_cat_Prod2.factorize()\n",
    "    BF_cat_Prod3_encoded, BF_categories_Prod3 = BF_cat_Prod3.factorize()\n",
    "\n",
    "\n",
    "   \n",
    "    if one_hot_cat:\n",
    "        BF_cat_Use_1hot = encoder.fit_transform(BF_cat_Use_encoded.reshape(-1,1))\n",
    "        BF_cat_Prod_1hot = encoder.fit_transform(BF_cat_Prod_encoded.reshape(-1,1))\n",
    "        BF_cat_Gen_1hot = encoder.fit_transform(BF_cat_Gen_encoded.reshape(-1,1))\n",
    "        BF_cat_Gen_1hot = encoder.fit_transform(BF_cat_Gen_encoded.reshape(-1,1))\n",
    "        BF_cat_Age_1hot = encoder.fit_transform(BF_cat_Age_encoded.reshape(-1,1))\n",
    "        BF_cat_CC_1hot = encoder.fit_transform(BF_cat_CC_encoded.reshape(-1,1))\n",
    "        BF_cat_SCCY_1hot = encoder.fit_transform(BF_cat_SCCY_encoded.reshape(-1,1))\n",
    "        BF_cat_MS_1hot = encoder.fit_transform(BF_cat_MS_encoded.reshape(-1,1))\n",
    "        BF_cat_Prod1_1hot = encoder.fit_transform(BF_cat_Prod1_encoded.reshape(-1,1))\n",
    "        BF_cat_Prod2_1hot = encoder.fit_transform(BF_cat_Prod2_encoded.reshape(-1,1))\n",
    "        BF_cat_Prod3_1hot = encoder.fit_transform(BF_cat_Prod3_encoded.reshape(-1,1))\n",
    "        \n",
    "        return np.c_[BF_cat_Use_1hot, BF_cat_Prod_1hot, BF_cat_Gen_1hot, BF_cat_Age_1hot, BF_cat_CC_1hot, BF_cat_SCCY_1hot,\n",
    "                     BF_cat_MS_1hot, BF_cat_Prod1_1hot, BF_cat_Prod2_1hot, BF_cat_Prod3_1hot]\n",
    "    else:\n",
    "        X[\"BF_cat_Use_cod\"] = X[\"User_ID\"].map(X.groupby(\"User_ID\").size())\n",
    "        X[\"BF_cat_Prod_cod\"] = X[\"Product_ID\"].map(X.groupby(\"Product_ID\").size())\n",
    "        X[\"BF_cat_Gen_cod\"] = X[\"Gender\"].map(X.groupby(\"Gender\").size())\n",
    "        X[\"BF_cat_Age_cod\"] = X[\"Age\"].map(X.groupby(\"Age\").size())\n",
    "        X[\"BF_cat_CC_cod\"] = X[\"City_Category\"].map(X.groupby(X[\"City_Category\"]).size())\n",
    "        X[\"BF_cat_SCCY_cod\"] = X[\"Stay_In_Current_City_Years\"].map(X.groupby(X[\"Stay_In_Current_City_Years\"]).size())\n",
    "        X[\"BF_cat_MS_cod\"] = X[\"Marital_Status\"].map(X.groupby(X[\"Marital_Status\"]).size())\n",
    "        X[\"BF_cat_Prod1_cod\"] = X[\"Product_Category_1\"].map(X.groupby(X[\"Product_Category_1\"]).size())\n",
    "        X[\"BF_cat_Prod2_cod\"] = X[\"Product_Category_2\"].map(X.groupby(X[\"Product_Category_2\"]).size())\n",
    "        X[\"BF_cat_Prod3_cod\"] = X[\"Product_Category_3\"].map(X.groupby(X[\"Product_Category_3\"]).size())\n",
    "        \n",
    "        return np.c_[X[\"BF_cat_Use_cod\"], X[\"BF_cat_Prod_cod\"], X[\"BF_cat_Gen_cod\"], X[\"BF_cat_Age_cod\"], X[\"BF_cat_CC_cod\"],\n",
    "                     X[\"BF_cat_SCCY_cod\"], X[\"BF_cat_MS_cod\"], X[\"BF_cat_Prod1_cod\"], X[\"BF_cat_Prod2_cod\"], X[\"BF_cat_Prod3_cod\"] ]\n",
    "\n",
    "#attr_coder = FunctionTransformer(coder_cat, validate=False,\n",
    "                                 #kw_args={\"one_hot_cat\": False, \"share_cat\": True})\n",
    "#BF_coder = attr_coder.fit_transform(BF_prep)\n",
    "#BF_coder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим pipeline для категориальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('coder',  FunctionTransformer(coder_cat, validate=False, kw_args={\"one_hot_cat\": False, \"share_cat\": True})),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "BF_prepared = cat_pipeline.fit_transform(BF_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6415357 ,  0.35457624,  0.53822887, ...,  0.90657471,\n",
       "         1.48603752, -0.28233173],\n",
       "       [-1.22388627,  0.29726541,  0.53822887, ..., -1.19027475,\n",
       "        -1.22887199,  1.40203722],\n",
       "       [-1.28212132, -0.53055776,  0.53822887, ..., -1.19027475,\n",
       "        -1.61398056, -0.26619818],\n",
       "       ...,\n",
       "       [ 0.17375509, -1.34246126,  0.53822887, ..., -1.00575252,\n",
       "        -0.26099096, -0.28233173],\n",
       "       [-0.8453584 ,  0.31636902,  0.53822887, ...,  0.90657471,\n",
       "        -0.52549417, -0.68818305],\n",
       "       [-0.05918514, -0.29813049,  0.53822887, ...,  0.90657471,\n",
       "        -1.26035828,  0.913799  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131600, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель линейной регрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(BF_prepared, BF_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опробуем полученную модель на нескольких образцах  из обучаещего набора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "some_data = BF_data.iloc[:5]\n",
    "some_labels = BF_labels.iloc[:5]\n",
    "some_data_prepared = cat_pipeline.fit_transform(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогнозы: [13203.13178225  9321.16754566  9208.74754784 13191.37016169\n",
      " 13394.29181514]\n"
     ]
    }
   ],
   "source": [
    "print(\"Прогнозы:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метки: [7585, 3998, 7964, 15334, 15773]\n"
     ]
    }
   ],
   "source": [
    "print(\"Метки:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель работает, но предсказания достаточно неточные. Вычисли ошибку RMSE этой модели на целом обучаещем наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4353.762142567611"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "BF_predictions = lin_reg.predict(BF_prepared)\n",
    "lin_mse = mean_squared_error(BF_labels, BF_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(BF_prepared, BF_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467.1091778961831"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_predictions = tree_reg.predict(BF_prepared)\n",
    "tree_mse = mean_squared_error(BF_labels, BF_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(BF_prepared, BF_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1520.5216485845901"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_predictions = forest_reg.predict(BF_prepared)\n",
    "forest_mse = mean_squared_error(BF_labels, BF_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVR\n",
    "#svr_reg = SVR()\n",
    "#svr_reg.fit(BF_prepared, BF_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BF_predictions = svr_reg.predict(BF_prepared)\n",
    "#svr_mse = mean_squared_error(BF_labels, BF_predictions)\n",
    "#svr_rmse = np.sqrt(svr_mse)\n",
    "#svr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка с использованием перекстной проверки(k-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, BF_prepared, BF_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lin_reg, BF_prepared, BF_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(forest_reg, BF_prepared, BF_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [4597.98094366 4637.62162071 4613.5636918  4575.10243327 4514.75245478\n",
      " 4574.65739502 4625.73071047 4596.46963504 4593.71524859 4569.08157597]\n",
      "Mean: 4589.867570932882\n",
      "Standard deviation: 32.826872962566696\n"
     ]
    }
   ],
   "source": [
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [4376.83212378 4382.91671277 4358.10397095 4382.82586491 4328.24737927\n",
      " 4332.98884652 4371.50770279 4366.09098259 4322.94031543 4318.54824859]\n",
      "Mean: 4354.100214759708\n",
      "Standard deviation: 24.462344602326\n"
     ]
    }
   ],
   "source": [
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [3556.22728719 3529.63865291 3553.60207021 3542.28330616 3523.79093195\n",
      " 3505.80346776 3546.82985803 3503.86448175 3525.47408839 3513.21095482]\n",
      "Mean: 3530.0725099165043\n",
      "Standard deviation: 18.134431240177673\n"
     ]
    }
   ],
   "source": [
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные результаты позволяют сделать вывод о том, что из приведенных моделей, лучшей является RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Точная настройка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим все возможные комбинации гиперпараметров для использованных моделей с помощью GridSearchCV. Первой проработаем модель, показувшую лучшие результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [50, 60, 70, 80], 'max_features': [2, 4, 6, 8]}, {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [50, 60, 70, 80], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(BF_prepared, BF_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 2, 'n_estimators': 80}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=80, n_jobs=1, oob_score=False, random_state=42,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3378.745798277235 {'max_features': 2, 'n_estimators': 50}\n",
      "3373.0904530196435 {'max_features': 2, 'n_estimators': 60}\n",
      "3369.408871044574 {'max_features': 2, 'n_estimators': 70}\n",
      "3365.794636061621 {'max_features': 2, 'n_estimators': 80}\n",
      "3378.1317654470186 {'max_features': 4, 'n_estimators': 50}\n",
      "3374.542475530636 {'max_features': 4, 'n_estimators': 60}\n",
      "3370.4280977796548 {'max_features': 4, 'n_estimators': 70}\n",
      "3367.437114192795 {'max_features': 4, 'n_estimators': 80}\n",
      "3391.7377805582637 {'max_features': 6, 'n_estimators': 50}\n",
      "3385.6955709331605 {'max_features': 6, 'n_estimators': 60}\n",
      "3382.375820492561 {'max_features': 6, 'n_estimators': 70}\n",
      "3380.751207307257 {'max_features': 6, 'n_estimators': 80}\n",
      "3401.629677960969 {'max_features': 8, 'n_estimators': 50}\n",
      "3397.551866767319 {'max_features': 8, 'n_estimators': 60}\n",
      "3394.4142458095916 {'max_features': 8, 'n_estimators': 70}\n",
      "3391.0909643359037 {'max_features': 8, 'n_estimators': 80}\n",
      "3906.378467247047 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "3643.6744233058453 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3879.3323554175445 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "3640.2583606623116 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "3890.4291749868767 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "3645.9246599866324 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.158981</td>\n",
       "      <td>0.677041</td>\n",
       "      <td>-1.141592e+07</td>\n",
       "      <td>-1.756337e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 50}</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.149205e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.134404e+07</td>\n",
       "      <td>-1.763064e+06</td>\n",
       "      <td>-1.145821e+07</td>\n",
       "      <td>-1.754982e+06</td>\n",
       "      <td>-1.126661e+07</td>\n",
       "      <td>-1.759139e+06</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>95510.504169</td>\n",
       "      <td>4209.247415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.461302</td>\n",
       "      <td>0.817441</td>\n",
       "      <td>-1.137774e+07</td>\n",
       "      <td>-1.735266e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 60}</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.146123e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.131853e+07</td>\n",
       "      <td>-1.740130e+06</td>\n",
       "      <td>-1.141848e+07</td>\n",
       "      <td>-1.736661e+06</td>\n",
       "      <td>-1.124020e+07</td>\n",
       "      <td>-1.740501e+06</td>\n",
       "      <td>0.431126</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>85221.585335</td>\n",
       "      <td>4881.327467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.544891</td>\n",
       "      <td>0.959002</td>\n",
       "      <td>-1.135292e+07</td>\n",
       "      <td>-1.720532e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 70}</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.144089e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.128875e+07</td>\n",
       "      <td>-1.723940e+06</td>\n",
       "      <td>-1.139179e+07</td>\n",
       "      <td>-1.722755e+06</td>\n",
       "      <td>-1.122136e+07</td>\n",
       "      <td>-1.724922e+06</td>\n",
       "      <td>0.841533</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>84162.582546</td>\n",
       "      <td>4160.360892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.377309</td>\n",
       "      <td>1.101362</td>\n",
       "      <td>-1.132857e+07</td>\n",
       "      <td>-1.707464e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 80}</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.141487e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.126594e+07</td>\n",
       "      <td>-1.710497e+06</td>\n",
       "      <td>-1.136218e+07</td>\n",
       "      <td>-1.710673e+06</td>\n",
       "      <td>-1.120132e+07</td>\n",
       "      <td>-1.712686e+06</td>\n",
       "      <td>0.344720</td>\n",
       "      <td>0.021161</td>\n",
       "      <td>81962.104662</td>\n",
       "      <td>4745.499360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.846584</td>\n",
       "      <td>0.686401</td>\n",
       "      <td>-1.141177e+07</td>\n",
       "      <td>-1.755335e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 50}</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.151857e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132698e+07</td>\n",
       "      <td>-1.762615e+06</td>\n",
       "      <td>-1.144697e+07</td>\n",
       "      <td>-1.757857e+06</td>\n",
       "      <td>-1.129658e+07</td>\n",
       "      <td>-1.761611e+06</td>\n",
       "      <td>0.234021</td>\n",
       "      <td>0.026104</td>\n",
       "      <td>85402.053559</td>\n",
       "      <td>6814.183787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.433069</td>\n",
       "      <td>0.814321</td>\n",
       "      <td>-1.138754e+07</td>\n",
       "      <td>-1.736767e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 60}</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.149290e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.130374e+07</td>\n",
       "      <td>-1.744753e+06</td>\n",
       "      <td>-1.141828e+07</td>\n",
       "      <td>-1.739982e+06</td>\n",
       "      <td>-1.126990e+07</td>\n",
       "      <td>-1.743640e+06</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>86227.641634</td>\n",
       "      <td>7599.717482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.219434</td>\n",
       "      <td>0.945362</td>\n",
       "      <td>-1.135979e+07</td>\n",
       "      <td>-1.721295e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 70}</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.147114e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.128347e+07</td>\n",
       "      <td>-1.727710e+06</td>\n",
       "      <td>-1.138271e+07</td>\n",
       "      <td>-1.723793e+06</td>\n",
       "      <td>-1.124289e+07</td>\n",
       "      <td>-1.727817e+06</td>\n",
       "      <td>0.047187</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>84721.708178</td>\n",
       "      <td>6554.984007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.868119</td>\n",
       "      <td>1.079522</td>\n",
       "      <td>-1.133963e+07</td>\n",
       "      <td>-1.709445e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 80}</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.144519e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.126698e+07</td>\n",
       "      <td>-1.715903e+06</td>\n",
       "      <td>-1.136027e+07</td>\n",
       "      <td>-1.713268e+06</td>\n",
       "      <td>-1.122345e+07</td>\n",
       "      <td>-1.716336e+06</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>82787.386517</td>\n",
       "      <td>7133.546072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.832912</td>\n",
       "      <td>0.680161</td>\n",
       "      <td>-1.150389e+07</td>\n",
       "      <td>-1.767613e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 50}</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.164510e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140401e+07</td>\n",
       "      <td>-1.773457e+06</td>\n",
       "      <td>-1.149121e+07</td>\n",
       "      <td>-1.764420e+06</td>\n",
       "      <td>-1.142181e+07</td>\n",
       "      <td>-1.777464e+06</td>\n",
       "      <td>0.052062</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>89069.404317</td>\n",
       "      <td>7325.893926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.375157</td>\n",
       "      <td>0.829921</td>\n",
       "      <td>-1.146293e+07</td>\n",
       "      <td>-1.747365e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 60}</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.161241e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135898e+07</td>\n",
       "      <td>-1.755090e+06</td>\n",
       "      <td>-1.143292e+07</td>\n",
       "      <td>-1.742429e+06</td>\n",
       "      <td>-1.139885e+07</td>\n",
       "      <td>-1.758663e+06</td>\n",
       "      <td>0.088467</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>90018.567565</td>\n",
       "      <td>8367.752043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.913244</td>\n",
       "      <td>0.957842</td>\n",
       "      <td>-1.144047e+07</td>\n",
       "      <td>-1.733187e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 70}</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.158827e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132626e+07</td>\n",
       "      <td>-1.740847e+06</td>\n",
       "      <td>-1.142042e+07</td>\n",
       "      <td>-1.727697e+06</td>\n",
       "      <td>-1.136037e+07</td>\n",
       "      <td>-1.743637e+06</td>\n",
       "      <td>0.121640</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>96058.319479</td>\n",
       "      <td>8010.540451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.332770</td>\n",
       "      <td>1.082642</td>\n",
       "      <td>-1.142948e+07</td>\n",
       "      <td>-1.722335e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 80}</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.156799e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132836e+07</td>\n",
       "      <td>-1.729603e+06</td>\n",
       "      <td>-1.141362e+07</td>\n",
       "      <td>-1.718903e+06</td>\n",
       "      <td>-1.134045e+07</td>\n",
       "      <td>-1.732654e+06</td>\n",
       "      <td>0.146141</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>91807.982940</td>\n",
       "      <td>7832.581427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.830679</td>\n",
       "      <td>0.680161</td>\n",
       "      <td>-1.157108e+07</td>\n",
       "      <td>-1.775358e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 50}</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.162475e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.152872e+07</td>\n",
       "      <td>-1.780663e+06</td>\n",
       "      <td>-1.158084e+07</td>\n",
       "      <td>-1.776949e+06</td>\n",
       "      <td>-1.144776e+07</td>\n",
       "      <td>-1.779607e+06</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>78021.856608</td>\n",
       "      <td>4846.858329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.615731</td>\n",
       "      <td>0.844942</td>\n",
       "      <td>-1.154336e+07</td>\n",
       "      <td>-1.755367e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 60}</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.161825e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149147e+07</td>\n",
       "      <td>-1.762441e+06</td>\n",
       "      <td>-1.154585e+07</td>\n",
       "      <td>-1.756757e+06</td>\n",
       "      <td>-1.142166e+07</td>\n",
       "      <td>-1.760165e+06</td>\n",
       "      <td>0.260342</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>80462.706437</td>\n",
       "      <td>5797.221059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30.796897</td>\n",
       "      <td>0.971042</td>\n",
       "      <td>-1.152205e+07</td>\n",
       "      <td>-1.741335e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 70}</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.160801e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.146020e+07</td>\n",
       "      <td>-1.747954e+06</td>\n",
       "      <td>-1.152242e+07</td>\n",
       "      <td>-1.741260e+06</td>\n",
       "      <td>-1.140153e+07</td>\n",
       "      <td>-1.746364e+06</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>83623.734369</td>\n",
       "      <td>5481.104855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35.450953</td>\n",
       "      <td>1.104644</td>\n",
       "      <td>-1.149950e+07</td>\n",
       "      <td>-1.730231e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 80}</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.158370e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.144244e+07</td>\n",
       "      <td>-1.735940e+06</td>\n",
       "      <td>-1.149656e+07</td>\n",
       "      <td>-1.732893e+06</td>\n",
       "      <td>-1.137744e+07</td>\n",
       "      <td>-1.735142e+06</td>\n",
       "      <td>0.246958</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>83456.923867</td>\n",
       "      <td>5674.380272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.890243</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>-1.525979e+07</td>\n",
       "      <td>-1.762052e+05</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.535662e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.518046e+07</td>\n",
       "      <td>-1.752841e+05</td>\n",
       "      <td>-1.549026e+07</td>\n",
       "      <td>-1.803051e+05</td>\n",
       "      <td>-1.521026e+07</td>\n",
       "      <td>-1.770397e+05</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>148736.798496</td>\n",
       "      <td>2298.378256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.958809</td>\n",
       "      <td>0.158681</td>\n",
       "      <td>-1.327636e+07</td>\n",
       "      <td>-1.762098e+05</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.331890e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.309169e+07</td>\n",
       "      <td>-1.752893e+05</td>\n",
       "      <td>-1.346883e+07</td>\n",
       "      <td>-1.803050e+05</td>\n",
       "      <td>-1.328120e+07</td>\n",
       "      <td>-1.770142e+05</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>123304.996641</td>\n",
       "      <td>2288.649142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.059365</td>\n",
       "      <td>0.048561</td>\n",
       "      <td>-1.504922e+07</td>\n",
       "      <td>-1.762067e+05</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>20</td>\n",
       "      <td>-1.504637e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.514102e+07</td>\n",
       "      <td>-1.752841e+05</td>\n",
       "      <td>-1.494367e+07</td>\n",
       "      <td>-1.803292e+05</td>\n",
       "      <td>-1.504981e+07</td>\n",
       "      <td>-1.770100e+05</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>62980.615561</td>\n",
       "      <td>2302.627492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.514493</td>\n",
       "      <td>0.159920</td>\n",
       "      <td>-1.325148e+07</td>\n",
       "      <td>-1.762069e+05</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.344482e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313936e+07</td>\n",
       "      <td>-1.753030e+05</td>\n",
       "      <td>-1.323046e+07</td>\n",
       "      <td>-1.803071e+05</td>\n",
       "      <td>-1.317657e+07</td>\n",
       "      <td>-1.770210e+05</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>106041.089859</td>\n",
       "      <td>2295.138162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.229484</td>\n",
       "      <td>0.053040</td>\n",
       "      <td>-1.513544e+07</td>\n",
       "      <td>-1.762516e+05</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.502469e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.502284e+07</td>\n",
       "      <td>-1.753101e+05</td>\n",
       "      <td>-1.529551e+07</td>\n",
       "      <td>-1.804621e+05</td>\n",
       "      <td>-1.501345e+07</td>\n",
       "      <td>-1.770090e+05</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>141265.823692</td>\n",
       "      <td>2336.596520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.059214</td>\n",
       "      <td>0.155841</td>\n",
       "      <td>-1.329277e+07</td>\n",
       "      <td>-1.762081e+05</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>19</td>\n",
       "      <td>-1.335978e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.324801e+07</td>\n",
       "      <td>-1.752899e+05</td>\n",
       "      <td>-1.333287e+07</td>\n",
       "      <td>-1.803321e+05</td>\n",
       "      <td>-1.317044e+07</td>\n",
       "      <td>-1.770090e+05</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>73021.711443</td>\n",
       "      <td>2303.131453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       10.158981         0.677041    -1.141592e+07     -1.756337e+06   \n",
       "1       12.461302         0.817441    -1.137774e+07     -1.735266e+06   \n",
       "2       14.544891         0.959002    -1.135292e+07     -1.720532e+06   \n",
       "3       16.377309         1.101362    -1.132857e+07     -1.707464e+06   \n",
       "4       13.846584         0.686401    -1.141177e+07     -1.755335e+06   \n",
       "5       16.433069         0.814321    -1.138754e+07     -1.736767e+06   \n",
       "6       19.219434         0.945362    -1.135979e+07     -1.721295e+06   \n",
       "7       21.868119         1.079522    -1.133963e+07     -1.709445e+06   \n",
       "8       17.832912         0.680161    -1.150389e+07     -1.767613e+06   \n",
       "9       21.375157         0.829921    -1.146293e+07     -1.747365e+06   \n",
       "10      24.913244         0.957842    -1.144047e+07     -1.733187e+06   \n",
       "11      28.332770         1.082642    -1.142948e+07     -1.722335e+06   \n",
       "12      21.830679         0.680161    -1.157108e+07     -1.775358e+06   \n",
       "13      26.615731         0.844942    -1.154336e+07     -1.755367e+06   \n",
       "14      30.796897         0.971042    -1.152205e+07     -1.741335e+06   \n",
       "15      35.450953         1.104644    -1.149950e+07     -1.730231e+06   \n",
       "16       0.890243         0.056160    -1.525979e+07     -1.762052e+05   \n",
       "17       2.958809         0.158681    -1.327636e+07     -1.762098e+05   \n",
       "18       1.059365         0.048561    -1.504922e+07     -1.762067e+05   \n",
       "19       3.514493         0.159920    -1.325148e+07     -1.762069e+05   \n",
       "20       1.229484         0.053040    -1.513544e+07     -1.762516e+05   \n",
       "21       4.059214         0.155841    -1.329277e+07     -1.762081e+05   \n",
       "\n",
       "   param_bootstrap param_max_features param_n_estimators  \\\n",
       "0              NaN                  2                 50   \n",
       "1              NaN                  2                 60   \n",
       "2              NaN                  2                 70   \n",
       "3              NaN                  2                 80   \n",
       "4              NaN                  4                 50   \n",
       "5              NaN                  4                 60   \n",
       "6              NaN                  4                 70   \n",
       "7              NaN                  4                 80   \n",
       "8              NaN                  6                 50   \n",
       "9              NaN                  6                 60   \n",
       "10             NaN                  6                 70   \n",
       "11             NaN                  6                 80   \n",
       "12             NaN                  8                 50   \n",
       "13             NaN                  8                 60   \n",
       "14             NaN                  8                 70   \n",
       "15             NaN                  8                 80   \n",
       "16           False                  2                  3   \n",
       "17           False                  2                 10   \n",
       "18           False                  3                  3   \n",
       "19           False                  3                 10   \n",
       "20           False                  4                  3   \n",
       "21           False                  4                 10   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "0             {'max_features': 2, 'n_estimators': 50}                8   \n",
       "1             {'max_features': 2, 'n_estimators': 60}                5   \n",
       "2             {'max_features': 2, 'n_estimators': 70}                3   \n",
       "3             {'max_features': 2, 'n_estimators': 80}                1   \n",
       "4             {'max_features': 4, 'n_estimators': 50}                7   \n",
       "5             {'max_features': 4, 'n_estimators': 60}                6   \n",
       "6             {'max_features': 4, 'n_estimators': 70}                4   \n",
       "7             {'max_features': 4, 'n_estimators': 80}                2   \n",
       "8             {'max_features': 6, 'n_estimators': 50}               13   \n",
       "9             {'max_features': 6, 'n_estimators': 60}               11   \n",
       "10            {'max_features': 6, 'n_estimators': 70}               10   \n",
       "11            {'max_features': 6, 'n_estimators': 80}                9   \n",
       "12            {'max_features': 8, 'n_estimators': 50}               16   \n",
       "13            {'max_features': 8, 'n_estimators': 60}               15   \n",
       "14            {'max_features': 8, 'n_estimators': 70}               14   \n",
       "15            {'max_features': 8, 'n_estimators': 80}               12   \n",
       "16  {'bootstrap': False, 'max_features': 2, 'n_est...               22   \n",
       "17  {'bootstrap': False, 'max_features': 2, 'n_est...               18   \n",
       "18  {'bootstrap': False, 'max_features': 3, 'n_est...               20   \n",
       "19  {'bootstrap': False, 'max_features': 3, 'n_est...               17   \n",
       "20  {'bootstrap': False, 'max_features': 4, 'n_est...               21   \n",
       "21  {'bootstrap': False, 'max_features': 4, 'n_est...               19   \n",
       "\n",
       "    split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0       -1.149205e+07       ...             -1.134404e+07       -1.763064e+06   \n",
       "1       -1.146123e+07       ...             -1.131853e+07       -1.740130e+06   \n",
       "2       -1.144089e+07       ...             -1.128875e+07       -1.723940e+06   \n",
       "3       -1.141487e+07       ...             -1.126594e+07       -1.710497e+06   \n",
       "4       -1.151857e+07       ...             -1.132698e+07       -1.762615e+06   \n",
       "5       -1.149290e+07       ...             -1.130374e+07       -1.744753e+06   \n",
       "6       -1.147114e+07       ...             -1.128347e+07       -1.727710e+06   \n",
       "7       -1.144519e+07       ...             -1.126698e+07       -1.715903e+06   \n",
       "8       -1.164510e+07       ...             -1.140401e+07       -1.773457e+06   \n",
       "9       -1.161241e+07       ...             -1.135898e+07       -1.755090e+06   \n",
       "10      -1.158827e+07       ...             -1.132626e+07       -1.740847e+06   \n",
       "11      -1.156799e+07       ...             -1.132836e+07       -1.729603e+06   \n",
       "12      -1.162475e+07       ...             -1.152872e+07       -1.780663e+06   \n",
       "13      -1.161825e+07       ...             -1.149147e+07       -1.762441e+06   \n",
       "14      -1.160801e+07       ...             -1.146020e+07       -1.747954e+06   \n",
       "15      -1.158370e+07       ...             -1.144244e+07       -1.735940e+06   \n",
       "16      -1.535662e+07       ...             -1.518046e+07       -1.752841e+05   \n",
       "17      -1.331890e+07       ...             -1.309169e+07       -1.752893e+05   \n",
       "18      -1.504637e+07       ...             -1.514102e+07       -1.752841e+05   \n",
       "19      -1.344482e+07       ...             -1.313936e+07       -1.753030e+05   \n",
       "20      -1.502469e+07       ...             -1.502284e+07       -1.753101e+05   \n",
       "21      -1.335978e+07       ...             -1.324801e+07       -1.752899e+05   \n",
       "\n",
       "    split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0       -1.145821e+07       -1.754982e+06      -1.126661e+07   \n",
       "1       -1.141848e+07       -1.736661e+06      -1.124020e+07   \n",
       "2       -1.139179e+07       -1.722755e+06      -1.122136e+07   \n",
       "3       -1.136218e+07       -1.710673e+06      -1.120132e+07   \n",
       "4       -1.144697e+07       -1.757857e+06      -1.129658e+07   \n",
       "5       -1.141828e+07       -1.739982e+06      -1.126990e+07   \n",
       "6       -1.138271e+07       -1.723793e+06      -1.124289e+07   \n",
       "7       -1.136027e+07       -1.713268e+06      -1.122345e+07   \n",
       "8       -1.149121e+07       -1.764420e+06      -1.142181e+07   \n",
       "9       -1.143292e+07       -1.742429e+06      -1.139885e+07   \n",
       "10      -1.142042e+07       -1.727697e+06      -1.136037e+07   \n",
       "11      -1.141362e+07       -1.718903e+06      -1.134045e+07   \n",
       "12      -1.158084e+07       -1.776949e+06      -1.144776e+07   \n",
       "13      -1.154585e+07       -1.756757e+06      -1.142166e+07   \n",
       "14      -1.152242e+07       -1.741260e+06      -1.140153e+07   \n",
       "15      -1.149656e+07       -1.732893e+06      -1.137744e+07   \n",
       "16      -1.549026e+07       -1.803051e+05      -1.521026e+07   \n",
       "17      -1.346883e+07       -1.803050e+05      -1.328120e+07   \n",
       "18      -1.494367e+07       -1.803292e+05      -1.504981e+07   \n",
       "19      -1.323046e+07       -1.803071e+05      -1.317657e+07   \n",
       "20      -1.529551e+07       -1.804621e+05      -1.501345e+07   \n",
       "21      -1.333287e+07       -1.803321e+05      -1.317044e+07   \n",
       "\n",
       "    split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0        -1.759139e+06      0.083770        0.007643    95510.504169   \n",
       "1        -1.740501e+06      0.431126        0.012480    85221.585335   \n",
       "2        -1.724922e+06      0.841533        0.015620    84162.582546   \n",
       "3        -1.712686e+06      0.344720        0.021161    81962.104662   \n",
       "4        -1.761611e+06      0.234021        0.026104    85402.053559   \n",
       "5        -1.743640e+06      0.037699        0.006240    86227.641634   \n",
       "6        -1.727817e+06      0.047187        0.007642    84721.708178   \n",
       "7        -1.716336e+06      0.069346        0.006240    82787.386517   \n",
       "8        -1.777464e+06      0.052062        0.007642    89069.404317   \n",
       "9        -1.758663e+06      0.088467        0.006240    90018.567565   \n",
       "10       -1.743637e+06      0.121640        0.007642    96058.319479   \n",
       "11       -1.732654e+06      0.146141        0.007642    91807.982940   \n",
       "12       -1.779607e+06      0.110132        0.007642    78021.856608   \n",
       "13       -1.760165e+06      0.260342        0.030741    80462.706437   \n",
       "14       -1.746364e+06      0.130641        0.016429    83623.734369   \n",
       "15       -1.735142e+06      0.246958        0.004994    83456.923867   \n",
       "16       -1.770397e+05      0.006813        0.007642   148736.798496   \n",
       "17       -1.770142e+05      0.011311        0.007076   123304.996641   \n",
       "18       -1.770100e+05      0.009320        0.002156    62980.615561   \n",
       "19       -1.770210e+05      0.033337        0.006042   106041.089859   \n",
       "20       -1.770090e+05      0.012820        0.007642   141265.823692   \n",
       "21       -1.770090e+05      0.021599        0.008695    73021.711443   \n",
       "\n",
       "    std_train_score  \n",
       "0       4209.247415  \n",
       "1       4881.327467  \n",
       "2       4160.360892  \n",
       "3       4745.499360  \n",
       "4       6814.183787  \n",
       "5       7599.717482  \n",
       "6       6554.984007  \n",
       "7       7133.546072  \n",
       "8       7325.893926  \n",
       "9       8367.752043  \n",
       "10      8010.540451  \n",
       "11      7832.581427  \n",
       "12      4846.858329  \n",
       "13      5797.221059  \n",
       "14      5481.104855  \n",
       "15      5674.380272  \n",
       "16      2298.378256  \n",
       "17      2288.649142  \n",
       "18      2302.627492  \n",
       "19      2295.138162  \n",
       "20      2336.596520  \n",
       "21      2303.131453  \n",
       "\n",
       "[22 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000C08DC88>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000C22A0B8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(BF_prepared, BF_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3376.6631387640123 {'max_features': 7, 'n_estimators': 180}\n",
      "3453.46909259253 {'max_features': 5, 'n_estimators': 15}\n",
      "3357.45171316887 {'max_features': 3, 'n_estimators': 72}\n",
      "3425.7976829867725 {'max_features': 5, 'n_estimators': 21}\n",
      "3380.5403197013243 {'max_features': 7, 'n_estimators': 122}\n",
      "3356.4904414076013 {'max_features': 3, 'n_estimators': 75}\n",
      "3354.2028233528454 {'max_features': 3, 'n_estimators': 88}\n",
      "3371.920396463749 {'max_features': 5, 'n_estimators': 100}\n",
      "3349.533406763263 {'max_features': 3, 'n_estimators': 150}\n",
      "4021.8306900881876 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6532.360798597556"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "data_test=strat_test_set.copy()\n",
    "data_test_prep = prepare(data_test, drop_col = True, drop_row = False, imputer1 = False)\n",
    "\n",
    "X_test = data_test_prep.drop(\"Purchase\", axis=1)\n",
    "y_test = data_test_prep[\"Purchase\"].copy()\n",
    "\n",
    "X_test_prepared = cat_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
